{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "engaged-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "raising-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \".\\\\data\\\\data_10.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "connected-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    with open(dataset_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    # convert lists into NumPy arrays\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blessed-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(test_size, valid_size):\n",
    "    \n",
    "    # load in the data\n",
    "    X, y = load_data(DATASET_PATH)\n",
    "    \n",
    "    # create the train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=10)\n",
    "    \n",
    "    # create the train-validation split\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n",
    "                                                          test_size=valid_size, \n",
    "                                                          random_state=10)\n",
    "    \n",
    "    # TensorFlow expects a 3D array (tensor as input):  (130, 13, 1)  \n",
    "    # So we need to add channel (depth) = 1\n",
    "    X_train = X_train[..., np.newaxis]  # now X_train is 4D -> (num_samples, 130, 13, 1)\n",
    "    X_valid = X_valid[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "variable-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    \n",
    "    # create model: CNN with 3 convolutional layers, following by max-pooling layers\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # flatten the output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \n",
    "    # create new figure object with 2 subplots\n",
    "    fig, ax = plt.subplots(2, figsize=(8,6), dpi=150)\n",
    "    \n",
    "    # 1. create accuracy subplot\n",
    "    ax[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    ax[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    ax[0].set_ylabel(\"Accuracy\")\n",
    "    ax[0].legend(loc=\"lower right\")\n",
    "    ax[0].set_title(\"Accuracy Evaluation\")\n",
    "    \n",
    "    # 2. create error subplot\n",
    "    ax[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    ax[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(\"Error\")\n",
    "    ax[1].legend(loc=\"upper right\")\n",
    "    ax[1].set_title(\"Error Evaluation\")    \n",
    "    \n",
    "    # display the two plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "exciting-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X, y):\n",
    "    \n",
    "    # augment X array with extra axis at the beginning\n",
    "    X = X[np.newaxis, ...]\n",
    "    \n",
    "    # determine the predicted values: y_pred = [ [0.2, 0.3, ...] ]\n",
    "    y_pred = model.predict(X)  # X is (130, 13, 1) but should be (n, 130, 13, 1)\n",
    "    \n",
    "    # extract index with max value\n",
    "    predicted_index = np.argmax(y_pred, axis=1)  # --> 1D array, index between 0 and 9; e.g. [4]\n",
    "    \n",
    "    # print the output\n",
    "    print(\"Expected index: {}, Predicted index: {}\".format(y, predicted_index) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-slovenia",
   "metadata": {},
   "source": [
    "* Create train, validation, and test sets\n",
    "* Build the CNN\n",
    "* Compile the CNN\n",
    "* Train the CNN\n",
    "* Evaluate the CNN on the test set\n",
    "* Make predictions on a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "quantitative-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation, and test sets \n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = prepare_datasets(0.25, 0.2)  # (test_size, valid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adolescent-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5985, 130, 13, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "actual-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the CNN model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "model = build_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "designed-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the network\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "regular-memphis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 18s 72ms/step - loss: 2.6459 - accuracy: 0.1667 - val_loss: 1.9123 - val_accuracy: 0.3133\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 10s 51ms/step - loss: 1.9050 - accuracy: 0.3267 - val_loss: 1.6351 - val_accuracy: 0.4102\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 1.7333 - accuracy: 0.3959 - val_loss: 1.4937 - val_accuracy: 0.4709\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 15s 81ms/step - loss: 1.5917 - accuracy: 0.4425 - val_loss: 1.3977 - val_accuracy: 0.5124\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 1.4670 - accuracy: 0.4774 - val_loss: 1.3396 - val_accuracy: 0.5097\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 1.3984 - accuracy: 0.4962 - val_loss: 1.2843 - val_accuracy: 0.5364\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 1.3470 - accuracy: 0.5152 - val_loss: 1.2394 - val_accuracy: 0.5484\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 14s 73ms/step - loss: 1.2791 - accuracy: 0.5412 - val_loss: 1.2042 - val_accuracy: 0.5618\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 1.2656 - accuracy: 0.5446 - val_loss: 1.1981 - val_accuracy: 0.5718\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 14s 76ms/step - loss: 1.2305 - accuracy: 0.5601 - val_loss: 1.1595 - val_accuracy: 0.5812\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 11s 60ms/step - loss: 1.1962 - accuracy: 0.5715 - val_loss: 1.1551 - val_accuracy: 0.5805\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 1.1529 - accuracy: 0.5887 - val_loss: 1.1127 - val_accuracy: 0.6045\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 13s 69ms/step - loss: 1.1232 - accuracy: 0.5990 - val_loss: 1.1046 - val_accuracy: 0.6032\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 12s 64ms/step - loss: 1.1125 - accuracy: 0.5910 - val_loss: 1.1084 - val_accuracy: 0.6112\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 1.1015 - accuracy: 0.6016 - val_loss: 1.0583 - val_accuracy: 0.6212\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 1.0647 - accuracy: 0.6104 - val_loss: 1.0539 - val_accuracy: 0.6179\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 1.0388 - accuracy: 0.6278 - val_loss: 1.0272 - val_accuracy: 0.6259\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 1.0151 - accuracy: 0.6365 - val_loss: 1.0358 - val_accuracy: 0.6279\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 11s 57ms/step - loss: 0.9732 - accuracy: 0.6547 - val_loss: 1.0055 - val_accuracy: 0.6460\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 11s 59ms/step - loss: 0.9714 - accuracy: 0.6592 - val_loss: 1.0268 - val_accuracy: 0.6333\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 11s 58ms/step - loss: 0.9492 - accuracy: 0.6662 - val_loss: 0.9727 - val_accuracy: 0.6526\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.9256 - accuracy: 0.6682 - val_loss: 0.9756 - val_accuracy: 0.6473\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.9405 - accuracy: 0.6656 - val_loss: 0.9674 - val_accuracy: 0.6627\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.9214 - accuracy: 0.6689 - val_loss: 0.9592 - val_accuracy: 0.6613\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.9077 - accuracy: 0.6661 - val_loss: 0.9430 - val_accuracy: 0.6713\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 11s 56ms/step - loss: 0.8660 - accuracy: 0.6893 - val_loss: 0.9340 - val_accuracy: 0.6680\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.8629 - accuracy: 0.6907 - val_loss: 0.9717 - val_accuracy: 0.6526\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.8651 - accuracy: 0.6962 - val_loss: 0.9186 - val_accuracy: 0.6820\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.8322 - accuracy: 0.6970 - val_loss: 0.9200 - val_accuracy: 0.6787\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.7838 - accuracy: 0.7277 - val_loss: 0.9078 - val_accuracy: 0.6767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cf1a85df40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the CNN\n",
    "model.fit(X_train, y_train,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32, \n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "elementary-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 12ms/step - loss: 0.8884 - accuracy: 0.6776\n",
      "Accuracy on test set is: 0.6776263117790222\n"
     ]
    }
   ],
   "source": [
    "# evaluate the CNN on the test set\n",
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy on test set is: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bronze-irish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected index: 1, Predicted index: [1]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on a small sample\n",
    "test_no = 87\n",
    "Xi = X_test[test_no]\n",
    "yi = y_test[test_no]\n",
    "predict(model, Xi, yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-presentation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
